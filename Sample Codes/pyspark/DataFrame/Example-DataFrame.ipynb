{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('SimpleDF').getOrCreate()     # Creating Spark Session Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['currency', 'value']\n",
    "inputdata = [('Euro', 90), ('Pound', 100), ('Yuan', 11), ('Yen', 2), ('US Dollar', 84), ('K Dinar', 242)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrame (df) using RDD (parallelize method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize(inputdata)\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covert RDD to DataFrame (This method create df without proper column names)\n",
    "df = rdd.toDF()\n",
    "#df.show()\n",
    "\n",
    "# Rename column using withColumnRenamed method\n",
    "# This method takes 2 parameters; first existing column name, second new column name\n",
    "df.withColumnRenamed(\"_1\", \"Currency\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame using createDataFrame method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass rdd as argument to createDataFrame method.\n",
    "# pass list of column names as argument to toDF() method\n",
    "df = spark.createDataFrame(rdd).toDF(*cols)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# createDataFrame by passing data and column names as arguments\n",
    "\n",
    "df = spark.createDataFrame(data=inputdata, schema=cols)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myschema = \"`Currency` STRING, `Value` INT\"\n",
    "df = spark.createDataFrame(data=inputdata, schema=myschema)\n",
    "df.printSchema()        #printSchema() display column names with corrosponding data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame using read() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('D:/Dataset/FIFA2022.csv', header=True, inferSchema = True)  # change path to your loaction\n",
    "#df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col, expr, udf, regexp_extract\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "movie = spark.read.csv('D:/Dataset/movie.csv', header=True, inferSchema=True)  # change path to your loaction\n",
    "movie.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.select('type').distinct().count()   # select() is used to get column/s from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.select('movieId', 'type').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col() gives column values of selected column\n",
    "\n",
    "movie.filter(col('movieId').between(20,30)).select('movieId','type').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "f_path = 'D:/deepak/daytoday/Sept 2022/ABD/QPs/Semester/Lab/Datasets/FIFA2022.csv'\n",
    "#fifa_df = spark.read.csv('D:/Dataset/FIFA2022.csv', header=True, inferSchema=True)\n",
    "fifa_df = spark.read.csv(f_path, header=True, inferSchema=True)\n",
    "\n",
    "fifa_df = fifa_df.na.drop()\n",
    "def mapGroup(country):\n",
    "    countryList = [['Netherlands', 'Senegal', 'Ecuador', 'Qatar'],\n",
    "                   ['Portugal', 'Uruguay', 'South Korea', 'Ghana'],\n",
    "                   ['Argentina', 'Mexico', 'Poland', 'Saudi Arabia'],\n",
    "                   ['France', 'Denmark', 'Tunisia', 'Australia'],\n",
    "                   ['Brazil', 'Switzerland', 'Serbia', 'Cameroon'],\n",
    "                   ['Belgium', 'Croatia', 'Morocco', 'Canada'],\n",
    "                   ['Spain', 'Germany', 'Japan', 'Costa Rica'],\n",
    "                   ['England', 'United States', 'Iran', 'Wales']                  \n",
    "                  ]\n",
    "    if country in countryList[0]:\n",
    "        return 'A'\n",
    "    elif country in countryList[1]:\n",
    "        return 'B'\n",
    "    elif country in countryList[2]:\n",
    "        return 'C'\n",
    "    elif country in countryList[3]:\n",
    "        return 'D'\n",
    "    elif country in countryList[4]:\n",
    "        return 'E'\n",
    "    elif country in countryList[5]:\n",
    "        return 'F'\n",
    "    elif country in countryList[6]:\n",
    "        return 'G'\n",
    "    elif country in countryList[7]:\n",
    "        return 'H'\n",
    "    \n",
    "group_udf = udf(mapGroup, StringType())\n",
    "fifa_group = fifa_df.withColumn('Group', group_udf(col('Team')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa_group.select('Team','Group').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
